{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "print(\"Starting Exploratory Data Analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check data types and missing values\n",
    "print(f\"\\nData Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Class distribution\n",
    "fraud_counts = df['Class'].value_counts()\n",
    "fraud_rate = (fraud_counts[1] / len(df)) * 100\n",
    "\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"Legitimate transactions: {fraud_counts[0]:,} ({100-fraud_rate:.2f}%)\")\n",
    "print(f\"Fraudulent transactions: {fraud_counts[1]:,} ({fraud_rate:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for Amount and Time\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Amount statistics\n",
    "amount_stats = df['Amount'].describe()\n",
    "print(\"\\nTransaction Amount Statistics:\")\n",
    "print(amount_stats)\n",
    "\n",
    "# Time statistics (convert to hours)\n",
    "df['Hour'] = (df['Time'] % 86400) / 3600\n",
    "time_stats = df['Hour'].describe()\n",
    "print(\"\\nTime Statistics (in hours from start):\")\n",
    "print(time_stats)\n",
    "\n",
    "# Fraud rate highlight\n",
    "print(f\"\\n⚠️  FRAUD RATE: {fraud_rate:.3f}% ⚠️\")\n",
    "print(f\"This is a highly imbalanced dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amount distribution comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Legitimate transactions\n",
    "legit_amounts = df[df['Class'] == 0]['Amount']\n",
    "legit_median = legit_amounts.median()\n",
    "\n",
    "axes[0].hist(legit_amounts, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(legit_median, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Median: ${legit_median:.2f}')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Transaction Amount ($)')\n",
    "axes[0].set_ylabel('Frequency (log scale)')\n",
    "axes[0].set_title(f'Legitimate Transactions\\nMedian Amount: ${legit_median:.2f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fraudulent transactions\n",
    "fraud_amounts = df[df['Class'] == 1]['Amount']\n",
    "fraud_median = fraud_amounts.median()\n",
    "\n",
    "axes[1].hist(fraud_amounts, bins=50, color='red', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(fraud_median, color='blue', linestyle='--', linewidth=2,\n",
    "                label=f'Median: ${fraud_median:.2f}')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Transaction Amount ($)')\n",
    "axes[1].set_ylabel('Frequency (log scale)')\n",
    "axes[1].set_title(f'Fraudulent Transactions\\nMedian Amount: ${fraud_median:.2f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Transaction Amount Distribution by Class', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Key Insight: Fraud median (${fraud_median:.2f}) vs Legitimate median (${legit_median:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze fraud patterns throughout the day\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Scatter plot of transactions\n",
    "legit_data = df[df['Class'] == 0].sample(n=10000, random_state=42)  # Sample for performance\n",
    "fraud_data = df[df['Class'] == 1]\n",
    "\n",
    "ax1.scatter(legit_data['Hour'], legit_data['Amount'], \n",
    "           alpha=0.3, s=2, c='blue', label='Legitimate')\n",
    "ax1.scatter(fraud_data['Hour'], fraud_data['Amount'], \n",
    "           alpha=0.8, s=10, c='red', label='Fraud')\n",
    "\n",
    "ax1.set_xlabel('Hour of Day')\n",
    "ax1.set_ylabel('Transaction Amount ($)', color='black')\n",
    "ax1.set_yscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "ax1.set_title('Fraud Patterns Throughout the Day', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Calculate hourly fraud rate\n",
    "hourly_fraud = df.groupby(df['Hour'].astype(int))['Class'].agg(['sum', 'count'])\n",
    "hourly_fraud['rate'] = (hourly_fraud['sum'] / hourly_fraud['count']) * 100\n",
    "\n",
    "# Add fraud rate line on secondary axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(hourly_fraud.index, hourly_fraud['rate'], \n",
    "         color='orange', linewidth=2, marker='o', label='Fraud Rate')\n",
    "ax2.set_ylabel('Fraud Rate (%)', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak fraud hours\n",
    "peak_hours = hourly_fraud.nlargest(3, 'rate').index.tolist()\n",
    "print(f\"Peak fraud hours: {peak_hours}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a copy for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Scale Amount and Time features\n",
    "scaler = StandardScaler()\n",
    "df_processed['scaled_amount'] = scaler.fit_transform(df[['Amount']])\n",
    "df_processed['scaled_time'] = scaler.fit_transform(df[['Time']])\n",
    "\n",
    "# Drop original Amount, Time, and Hour columns\n",
    "df_processed = df_processed.drop(['Amount', 'Time', 'Hour'], axis=1)\n",
    "\n",
    "print(\"✓ Features scaled\")\n",
    "\n",
    "# Create train-test split with stratification\n",
    "X = df_processed.drop('Class', axis=1)\n",
    "y = df_processed['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"✓ Train-test split created\")\n",
    "print(f\"  Training set: {len(X_train):,} samples\")\n",
    "print(f\"  Test set: {len(X_test):,} samples\")\n",
    "\n",
    "# Save preprocessed data and indices\n",
    "df_processed.to_csv('../data/preprocessed_creditcard.csv', index=False)\n",
    "train_indices = X_train.index.tolist()\n",
    "test_indices = X_test.index.tolist()\n",
    "np.save('../data/train_indices.npy', train_indices)\n",
    "np.save('../data/test_indices.npy', test_indices)\n",
    "\n",
    "print(\"✓ Data saved for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dashboard\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"        DATASET OVERVIEW - FRAUD DETECTION DEMO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Transactions: {len(df):,}\")\n",
    "print(f\"Fraud Rate: {fraud_rate:.3f}%\")\n",
    "print(f\"Legitimate Median Amount: ${legit_median:.2f}\")\n",
    "print(f\"Fraud Median Amount: ${fraud_median:.2f}\")\n",
    "print(f\"Peak Fraud Hours: {peak_hours}\")\n",
    "print(f\"Training Set Size: {len(X_train):,}\")\n",
    "print(f\"Test Set Size: {len(X_test):,}\")\n",
    "print(f\"Total Features: {X_train.shape[1]}\")\n",
    "print(f\"Execution Time: {elapsed_time:.2f} seconds\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✅ Segment 1 Complete! Ready for baseline model development.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}